[
	{
		"id": "http://zotero.org/users/9765969/items/BNVGNM2L",
		"type": "paper-conference",
		"abstract": "While deep learning is a valuable tool for solving many tough problems in computer vision, the success of deep learning models is typically determined by: (i) availability of sufﬁcient training data, (ii) access to extensive computational resources, and (iii) expertise in selecting the right model and hyperparameters for the selected task. Often, the availability of data is the hard part due to compliance, legal, and privacy constraints. Cryptographic techniques such as fully homomorphic encryption (FHE) offer a potential solution by enabling processing on encrypted data. While prior work has been done on using FHE for inferencing, training a deep neural network in the encrypted domain is an extremely challenging task due to the computational complexity of the operations involved. In this paper, we evaluate the feasibility of training neural networks on encrypted data in a completely non-interactive way. Our proposed system uses the open-source FHE toolkit HElib to implement a Stochastic Gradient Descent (SGD)-based training of a neural network. We show that encrypted training can be made more computationally efﬁcient by (i) simplifying the network with minimal degradation of accuracy, (ii) choosing appropriate data representation and resolution, and (iii) packing the data elements within the ciphertext in a smart way so as to minimize the number of operations and facilitate parallelization of FHE computations. Based on the above optimizations, we demonstrate that it is possible to achieve more than 50× speed up while training a fully-connected neural network on the MNIST dataset while achieving reasonable accuracy (96%). Though the cost of training a complex deep learning model from scratch on encrypted data is still very high, this work establishes a solid baseline and paves the way for relatively simpler tasks such as ﬁne-tuning of deep learning models based on encrypted data to be implemented in the near future.",
		"container-title": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
		"DOI": "10.1109/CVPRW.2019.00011",
		"event-place": "Long Beach, CA, USA",
		"event-title": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
		"ISBN": "978-1-72812-506-0",
		"language": "en",
		"page": "40-48",
		"publisher": "IEEE",
		"publisher-place": "Long Beach, CA, USA",
		"source": "DOI.org (Crossref)",
		"title": "Towards Deep Neural Network Training on Encrypted Data",
		"URL": "https://ieeexplore.ieee.org/document/9025601/",
		"author": [
			{
				"family": "Nandakumar",
				"given": "Karthik"
			},
			{
				"family": "Ratha",
				"given": "Nalini"
			},
			{
				"family": "Pankanti",
				"given": "Sharath"
			},
			{
				"family": "Halevi",
				"given": "Shai"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2022",
					9,
					29
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2019",
					6
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/H2FIAW87",
		"type": "paper-conference",
		"abstract": "Information on air-quality in urban environments is typically measured only at limited number of sites, due to cost of measurement of atmospheric concentrations of toxic gases (CO, NO2, SO2) within accuracy boundaries defined by regulative bodies. Low spatial resolution of the mentioned environmental parameters hinders their applications in localization of the air-pollution sources, traffic regulation or studies of chronic respiratory diseases related to personal pollution exposure. Thus, we propose complementing the existing air quality monitoring infrastructure by a network of mobile sensors enabling the citizens to participate in measurement (e.g. “crowdsensing”). In this paper, we present the design of such battery-powered, wearable sensor node, housing two electrochemical gas sensors, temperature, relative humidity and atmospheric pressure sensors, with Bluetooth connectivity. Electrical, mechanical and software design are shown. Next, sensor node was characterized by evaluating the sensing accuracy and the autonomy in laboratory conditions. Accuracy within ±1 °C, ±2% RH, ±2 hPa, and ±0.6 ppm CO is shown. Autonomy is estimated at 65 h. Preliminary results of the outdoor functional test are demonstrated.",
		"container-title": "2015 IEEE Sensors Applications Symposium (SAS)",
		"DOI": "10.1109/SAS.2015.7133628",
		"event-title": "2015 IEEE Sensors Applications Symposium (SAS)",
		"page": "1-5",
		"source": "IEEE Xplore",
		"title": "Design of sensor node for air quality crowdsensing",
		"author": [
			{
				"family": "Oletic",
				"given": "Dinko"
			},
			{
				"family": "Bilas",
				"given": "Vedran"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2015",
					4
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/ERWP7F9C",
		"type": "article-journal",
		"abstract": "This paper proposes CrowdTracker, a novel object tracking system based on mobile crowd sensing (MCS). Different from traditional video-based object tracking approaches, CrowdTracker recruits people to collaboratively take photographs of the object to achieve object movement prediction and tracking. The optimization objective of CrowdTracker is to effectively track the moving object in real time and minimize the cost on user incentives. Specifically, the incentive is determined by the number of workers assigned and the total distance that workers move to complete the task. In order to achieve the objective, we propose the movement prediction (MPRE) model for object movement prediction and two other algorithms for task allocation, namely, T-centric and P-centric. T-centric selects workers in a task-centric way, while P-centric allocates tasks in a peoplecentric manner. By analyzing a large number of historical vehicle trajectories, MPRE builds a model to predict the object's next position. In the predicted regions, CrowdTracker selects workers by utilizing T-centric or P-centric. We evaluate the algorithms over a large-scale real-world dataset. Experimental results indicate that CrowdTracker can effectively track the object with a low incentive cost.",
		"container-title": "IEEE Internet of Things Journal",
		"DOI": "10.1109/JIOT.2017.2762003",
		"ISSN": "2327-4662",
		"issue": "5",
		"note": "event-title: IEEE Internet of Things Journal",
		"page": "3452-3463",
		"source": "IEEE Xplore",
		"title": "CrowdTracker: Optimized Urban Moving Object Tracking Using Mobile Crowd Sensing",
		"title-short": "CrowdTracker",
		"volume": "5",
		"author": [
			{
				"family": "Jing",
				"given": "Yao"
			},
			{
				"family": "Guo",
				"given": "Bin"
			},
			{
				"family": "Wang",
				"given": "Zhu"
			},
			{
				"family": "Li",
				"given": "Victor O. K."
			},
			{
				"family": "Lam",
				"given": "Jacqueline C. K."
			},
			{
				"family": "Yu",
				"given": "Zhiwen"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2018",
					10
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/H9GIUPXG",
		"type": "article-journal",
		"abstract": "The advances in cloud computing and internet of things (IoT) have provided a promising opportunity to resolve the challenges caused by the increasing transportation issues. We present a novel multilayered vehicular data cloud platform by using cloud computing and IoT technologies. Two innovative vehicular data cloud services, an intelligent parking cloud service and a vehicular data mining cloud service, for vehicle warranty analysis in the IoT environment are also presented. Two modified data mining models for the vehicular data mining cloud service, a Naïve Bayes model and a Logistic Regression model, are presented in detail. Challenges and directions for future work are also provided.",
		"container-title": "IEEE Transactions on Industrial Informatics",
		"DOI": "10.1109/TII.2014.2299233",
		"ISSN": "1941-0050",
		"issue": "2",
		"note": "event-title: IEEE Transactions on Industrial Informatics",
		"page": "1587-1595",
		"source": "IEEE Xplore",
		"title": "Developing Vehicular Data Cloud Services in the IoT Environment",
		"volume": "10",
		"author": [
			{
				"family": "He",
				"given": "Wu"
			},
			{
				"family": "Yan",
				"given": "Gongjun"
			},
			{
				"family": "Xu",
				"given": "Li Da"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2014",
					5
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/HVYMLZHJ",
		"type": "article-journal",
		"abstract": "The communication and networking field is hungry for machine learning decision-making solutions to replace the traditional model-driven approaches that proved to be not rich enough for seizing the ever-growing complexity and heterogeneity of the modern systems in the field. Traditional machine learning solutions assume the existence of (cloud-based) central entities that are in charge of processing the data. Nonetheless, the difficulty of accessing private data, together with the high cost of transmitting raw data to the central entity gave rise to a decentralized machine learning approach called Federated Learning. The main idea of federated learning is to perform an on-device collaborative training of a single machine learning model without having to share the raw training data with any third-party entity. Although few survey articles on federated learning already exist in the literature, the motivation of this survey stems from three essential observations. The first one is the lack of a fine-grained multi-level classification of the federated learning literature, where the existing surveys base their classification on only one criterion or aspect. The second observation is that the existing surveys focus only on some common challenges, but disregard other essential aspects such as reliable client selection, resource management and training service pricing. The third observation is the lack of explicit and straightforward directives for researchers to help them design future federated learning solutions that overcome the state-of-the-art research gaps. To address these points, we first provide a comprehensive tutorial on federated learning and its associated concepts, technologies and learning approaches. We then survey and highlight the applications and future directions of federated learning in the domain of communication and networking. Thereafter, we design a three-level classification scheme that first categorizes the federated learning literature based on the high-level challenge that they tackle. Then, we classify each high-level challenge into a set of specific low-level challenges to foster a better understanding of the topic. Finally, we provide, within each low-level challenge, a fine-grained classification based on the technique used to address this particular challenge. For each category of high-level challenges, we provide a set of desirable criteria and future research directions that are aimed to help the research community design innovative and efficient future solutions. To the best of our knowledge, our survey is the most comprehensive in terms of challenges and techniques it covers and the most fine-grained in terms of the multi-level classification scheme it presents.",
		"container-title": "IEEE Communications Surveys & Tutorials",
		"DOI": "10.1109/COMST.2021.3058573",
		"ISSN": "1553-877X",
		"issue": "2",
		"note": "event-title: IEEE Communications Surveys & Tutorials",
		"page": "1342-1397",
		"source": "IEEE Xplore",
		"title": "Federated Machine Learning: Survey, Multi-Level Classification, Desirable Criteria and Future Directions in Communication and Networking Systems",
		"title-short": "Federated Machine Learning",
		"volume": "23",
		"author": [
			{
				"family": "Wahab",
				"given": "Omar Abdel"
			},
			{
				"family": "Mourad",
				"given": "Azzam"
			},
			{
				"family": "Otrok",
				"given": "Hadi"
			},
			{
				"family": "Taleb",
				"given": "Tarik"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2021"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/F3N2CZ43",
		"type": "article-journal",
		"abstract": "Wearable and mobile devices are widely used for crowdsensing, as they come with many sensors and are carried everywhere. Among the sensing data, videos annotated with temporal-spatial metadata contain huge amount of information, but consume too much precious storage space. In this paper, we solve the problem of optimizing cloud-based video crowdsensing in three steps. First, we study the optimal transcoding problem on wearable and mobile cameras. We propose an algorithm to optimally select the coding parameters to fit more videos at higher quality on wearable and mobile cameras. Second, we empirically investigate the throughput of different file transfer protocols from wearable and mobile devices to cloud servers. We propose a real-time algorithm to select the best protocol under diverse network conditions, so as to leverage the intermittent WiFi access. Last, we look into the performance of cloud databases for sensor-annotated videos, and implement a practical algorithm to search videos overlapping with a target geographical region. Our measurement study on three popular opensource cloud databases reveals their pros and cons. The three proposed algorithms are evaluated via extensive simulations and experiments. The evaluation results show the practicality and efficiency of our algorithms and system. For example, our proposed transcoding algorithm outperforms existing approaches by 12 dB in video quality, 87% in energy saving, and one-quarter in delivery delay. Another example is, by intelligently choosing a proper cloud database, our system may reduce the insertion time by up to one-third, or the lookup time by up to one-fourth.",
		"container-title": "IEEE Internet of Things Journal",
		"DOI": "10.1109/JIOT.2016.2519502",
		"ISSN": "2327-4662",
		"issue": "3",
		"note": "event-title: IEEE Internet of Things Journal",
		"page": "299-313",
		"source": "IEEE Xplore",
		"title": "Optimizing Cloud-Based Video Crowdsensing",
		"volume": "3",
		"author": [
			{
				"family": "Hong",
				"given": "Hua-Jun"
			},
			{
				"family": "Fan",
				"given": "Ching-Ling"
			},
			{
				"family": "Lin",
				"given": "Yen-Chen"
			},
			{
				"family": "Hsu",
				"given": "Cheng-Hsin"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2016",
					6
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/VSD3S97V",
		"type": "book",
		"collection-title": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
		"event-place": "Cham",
		"ISBN": "978-3-031-00457-5",
		"language": "en",
		"note": "DOI: 10.1007/978-3-031-01585-4",
		"publisher": "Springer International Publishing",
		"publisher-place": "Cham",
		"source": "DOI.org (Crossref)",
		"title": "Federated Learning",
		"URL": "https://link.springer.com/10.1007/978-3-031-01585-4",
		"author": [
			{
				"family": "Yang",
				"given": "Qiang"
			},
			{
				"family": "Liu",
				"given": "Yang"
			},
			{
				"family": "Cheng",
				"given": "Yong"
			},
			{
				"family": "Kang",
				"given": "Yan"
			},
			{
				"family": "Chen",
				"given": "Tianjian"
			},
			{
				"family": "Yu",
				"given": "Han"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2022",
					10,
					27
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2020"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/K7V96YM8",
		"type": "article",
		"abstract": "Federated Learning is a machine learning setting where the goal is to train a high-quality centralized model while training data remains distributed over a large number of clients each with unreliable and relatively slow network connections. We consider learning algorithms for this setting where on each round, each client independently computes an update to the current model based on its local data, and communicates this update to a central server, where the client-side updates are aggregated to compute a new global model. The typical clients in this setting are mobile phones, and communication efficiency is of the utmost importance. In this paper, we propose two ways to reduce the uplink communication costs: structured updates, where we directly learn an update from a restricted space parametrized using a smaller number of variables, e.g. either low-rank or a random mask; and sketched updates, where we learn a full model update and then compress it using a combination of quantization, random rotations, and subsampling before sending it to the server. Experiments on both convolutional and recurrent networks show that the proposed methods can reduce the communication cost by two orders of magnitude.",
		"DOI": "10.48550/arXiv.1610.05492",
		"note": "arXiv:1610.05492 [cs]",
		"number": "arXiv:1610.05492",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Federated Learning: Strategies for Improving Communication Efficiency",
		"title-short": "Federated Learning",
		"URL": "http://arxiv.org/abs/1610.05492",
		"author": [
			{
				"family": "Konečný",
				"given": "Jakub"
			},
			{
				"family": "McMahan",
				"given": "H. Brendan"
			},
			{
				"family": "Yu",
				"given": "Felix X."
			},
			{
				"family": "Richtárik",
				"given": "Peter"
			},
			{
				"family": "Suresh",
				"given": "Ananda Theertha"
			},
			{
				"family": "Bacon",
				"given": "Dave"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2022",
					10,
					27
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2017",
					10,
					30
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/KIIH56K9",
		"type": "paper-conference",
		"container-title": "10th USENIX Symposium on Networked Systems Design and Implementation (NSDI 13)",
		"page": "185–198",
		"source": "Google Scholar",
		"title": "Effective straggler mitigation: Attack of the clones",
		"title-short": "Effective straggler mitigation",
		"author": [
			{
				"family": "Ananthanarayanan",
				"given": "Ganesh"
			},
			{
				"family": "Ghodsi",
				"given": "Ali"
			},
			{
				"family": "Shenker",
				"given": "Scott"
			},
			{
				"family": "Stoica",
				"given": "Ion"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2013"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/7ALGVTR3",
		"type": "paper-conference",
		"container-title": "The 2014 ACM international conference on Measurement and modeling of computer systems",
		"page": "599–600",
		"source": "Google Scholar",
		"title": "Efficient task replication for fast response times in parallel computation",
		"author": [
			{
				"family": "Wang",
				"given": "Da"
			},
			{
				"family": "Joshi",
				"given": "Gauri"
			},
			{
				"family": "Wornell",
				"given": "Gregory"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2014"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/EZ7YNLZR",
		"type": "paper-conference",
		"container-title": "International Conference on Machine Learning",
		"page": "3368–3376",
		"publisher": "PMLR",
		"source": "Google Scholar",
		"title": "Gradient coding: Avoiding stragglers in distributed learning",
		"title-short": "Gradient coding",
		"author": [
			{
				"family": "Tandon",
				"given": "Rashish"
			},
			{
				"family": "Lei",
				"given": "Qi"
			},
			{
				"family": "Dimakis",
				"given": "Alexandros G."
			},
			{
				"family": "Karampatziakis",
				"given": "Nikos"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2017"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/HNYT38IF",
		"type": "article-journal",
		"container-title": "IEEE Transactions on Information Theory",
		"issue": "3",
		"note": "publisher: IEEE",
		"page": "1514–1529",
		"source": "Google Scholar",
		"title": "Speeding up distributed machine learning using codes",
		"volume": "64",
		"author": [
			{
				"family": "Lee",
				"given": "Kangwook"
			},
			{
				"family": "Lam",
				"given": "Maximilian"
			},
			{
				"family": "Pedarsani",
				"given": "Ramtin"
			},
			{
				"family": "Papailiopoulos",
				"given": "Dimitris"
			},
			{
				"family": "Ramchandran",
				"given": "Kannan"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2017"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/PL7IB42C",
		"type": "article-journal",
		"abstract": "Federated learning enables training a global model from data located at the client nodes, without data sharing and moving client data to a centralized server. Performance of federated learning in a multi-access edge computing (MEC) network suffers from slow convergence due to heterogeneity and stochastic fluctuations in compute power and communication link qualities across clients. We propose a novel coded computing framework, CodedFedL, that injects structured coding redundancy into federated learning for mitigating stragglers and speeding up the training procedure. CodedFedL enables coded computing for non-linear federated learning by efficiently exploiting distributed kernel embedding via random Fourier features that transforms the training task into computationally favourable distributed linear regression. Furthermore, clients generate local parity datasets by coding over their local datasets, while the server combines them to obtain the global parity dataset. Gradient from the global parity dataset compensates for straggling gradients during training, and thereby speeds up convergence. For minimizing the epoch deadline time at the MEC server, we provide a tractable approach for finding the amount of coding redundancy and the number of local data points that a client processes during training, by exploiting the statistical properties of compute as well as communication delays. We also characterize the leakage in data privacy when clients share their local parity datasets with the server. Additionally, we analyze the convergence rate and iteration complexity of CodedFedL under simplifying assumptions, by treating CodedFedL as a stochastic gradient descent algorithm. Finally, for demonstrating gains that CodedFedL can achieve in practice, we conduct numerical experiments using practical network parameters and benchmark datasets, in which CodedFedL speeds up the overall training time by up to 15× in comparison to the benchmark schemes.",
		"container-title": "IEEE Journal on Selected Areas in Communications",
		"DOI": "10.1109/JSAC.2020.3036961",
		"ISSN": "1558-0008",
		"issue": "1",
		"note": "event-title: IEEE Journal on Selected Areas in Communications",
		"page": "233-250",
		"source": "IEEE Xplore",
		"title": "Coded Computing for Low-Latency Federated Learning Over Wireless Edge Networks",
		"volume": "39",
		"author": [
			{
				"family": "Prakash",
				"given": "Saurav"
			},
			{
				"family": "Dhakal",
				"given": "Sagar"
			},
			{
				"family": "Akdeniz",
				"given": "Mustafa Riza"
			},
			{
				"family": "Yona",
				"given": "Yair"
			},
			{
				"family": "Talwar",
				"given": "Shilpa"
			},
			{
				"family": "Avestimehr",
				"given": "Salman"
			},
			{
				"family": "Himayat",
				"given": "Nageen"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2021",
					1
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/7EWAYAAZ",
		"type": "article-journal",
		"abstract": "When applying machine learning techniques to the Internet of things, aggregating massive amount of data seriously reduce the system efficiency. To tackle this challenge, a distributed learning framework called federated learning has been proposed. Due to the parallel training structure, the performance of federated learning suffers from the straggler effect. In this paper, to mitigate the straggler effect, we propose a novel learning scheme, edge-assisted federated learning (EAFL), which utilizes edge computing to reduce the computational burdens for stragglers in federated learning. It enables stragglers to offload partial computation to the edge server, and leverages the server's idle computing power to assist clients in model training. The offloading data size is optimized to minimize the learning delay of the system. Based on the optimized data size, a threshold-based offloading strategy for EAFL is proposed. Moreover, we extend EAFL to a dynamic scenario where clients may be offline after several update rounds. By grouping clients into different sets, we formulate the new EAFL delay optimization problem and derive the corresponding offloading strategy for the dynamic scenario. Simulation results are presented to show that EAFL has lower system delay than the original federated learning scheme.",
		"container-title": "IEEE Transactions on Vehicular Technology",
		"DOI": "10.1109/TVT.2021.3098022",
		"ISSN": "1939-9359",
		"issue": "9",
		"note": "event-title: IEEE Transactions on Vehicular Technology",
		"page": "9330-9344",
		"source": "IEEE Xplore",
		"title": "Computation Offloading for Edge-Assisted Federated Learning",
		"volume": "70",
		"author": [
			{
				"family": "Ji",
				"given": "Zhongming"
			},
			{
				"family": "Chen",
				"given": "Li"
			},
			{
				"family": "Zhao",
				"given": "Nan"
			},
			{
				"family": "Chen",
				"given": "Yunfei"
			},
			{
				"family": "Wei",
				"given": "Guo"
			},
			{
				"family": "Yu",
				"given": "F. Richard"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2021",
					9
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/UYNQPZFT",
		"type": "article",
		"abstract": "Applying Federated Learning (FL) on Internet-of-Things devices is necessitated by the large volumes of data they produce and growing concerns of data privacy. However, there are three challenges that need to be addressed to make FL efficient: (i) execution on devices with limited computational capabilities, (ii) accounting for stragglers due to computational heterogeneity of devices, and (iii) adaptation to the changing network bandwidths. This paper presents FedAdapt, an adaptive offloading FL framework to mitigate the aforementioned challenges. FedAdapt accelerates local training in computationally constrained devices by leveraging layer offloading of deep neural networks (DNNs) to servers. Further, FedAdapt adopts reinforcement learning based optimization and clustering to adaptively identify which layers of the DNN should be offloaded for each individual device on to a server to tackle the challenges of computational heterogeneity and changing network bandwidth. Experimental studies are carried out on a lab-based testbed and it is demonstrated that by offloading a DNN from the device to the server FedAdapt reduces the training time of a typical IoT device by over half compared to classic FL. The training time of extreme stragglers and the overall training time can be reduced by up to 57%. Furthermore, with changing network bandwidth, FedAdapt is demonstrated to reduce the training time by up to 40% when compared to classic FL, without sacrificing accuracy.",
		"DOI": "10.48550/arXiv.2107.04271",
		"note": "arXiv:2107.04271 [cs]",
		"number": "arXiv:2107.04271",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "FedAdapt: Adaptive Offloading for IoT Devices in Federated Learning",
		"title-short": "FedAdapt",
		"URL": "http://arxiv.org/abs/2107.04271",
		"author": [
			{
				"family": "Wu",
				"given": "Di"
			},
			{
				"family": "Ullah",
				"given": "Rehmat"
			},
			{
				"family": "Harvey",
				"given": "Paul"
			},
			{
				"family": "Kilpatrick",
				"given": "Peter"
			},
			{
				"family": "Spence",
				"given": "Ivor"
			},
			{
				"family": "Varghese",
				"given": "Blesson"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2022",
					10,
					29
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2022",
					5,
					18
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/CVL9W3P7",
		"type": "paper-conference",
		"container-title": "Proceedings of the AAAI Conference on Artificial Intelligence",
		"note": "issue: 8",
		"page": "8485–8493",
		"source": "Google Scholar",
		"title": "Splitfed: When federated learning meets split learning",
		"title-short": "Splitfed",
		"volume": "36",
		"author": [
			{
				"family": "Thapa",
				"given": "Chandra"
			},
			{
				"family": "Arachchige",
				"given": "Pathum Chamikara Mahawaga"
			},
			{
				"family": "Camtepe",
				"given": "Seyit"
			},
			{
				"family": "Sun",
				"given": "Lichao"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2022"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/WMSD257J",
		"type": "paper-conference",
		"abstract": "Federated learning (FL) is a machine learning paradigm where a shared central model is learned across distributed devices while the training data remains on these devices. Federated Averaging (FedAvg) is the leading optimization method for training non-convex models in this setting with a synchronized protocol. However, the assumptions made by FedAvg are not realistic given the heterogeneity of devices. First, the volume and distribution of collected data vary in the training process due to different sampling rates of edge devices. Second, the edge devices themselves also vary in latency and system configurations, such as memory, processor speed, and power requirements. This leads to vastly different computation times. Third, availability issues at edge devices can lead to a lack of contribution from specific edge devices to the federated model. In this paper, we present an Asynchronous Online Federated Learning (ASO-Fed) framework, where the edge devices perform online learning with continuous streaming local data and a central server aggregates model parameters from clients. Our framework updates the central model in an asynchronous manner to tackle the challenges associated with both varying computational loads at heterogeneous edge devices and edge devices that lag behind or dropout. We perform extensive experiments on a benchmark image dataset and three real-world datasets with non-IID streaming data. The results demonstrate ASO-Fed converging fast and maintaining good prediction performance.",
		"container-title": "2020 IEEE International Conference on Big Data (Big Data)",
		"DOI": "10.1109/BigData50022.2020.9378161",
		"event-title": "2020 IEEE International Conference on Big Data (Big Data)",
		"page": "15-24",
		"source": "IEEE Xplore",
		"title": "Asynchronous Online Federated Learning for Edge Devices with Non-IID Data",
		"author": [
			{
				"family": "Chen",
				"given": "Yujing"
			},
			{
				"family": "Ning",
				"given": "Yue"
			},
			{
				"family": "Slawski",
				"given": "Martin"
			},
			{
				"family": "Rangwala",
				"given": "Huzefa"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2020",
					12
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/6A7MWCFR",
		"type": "article-journal",
		"container-title": "Future Generation Computer Systems",
		"note": "publisher: Elsevier",
		"page": "1–12",
		"source": "Google Scholar",
		"title": "FedSA: A staleness-aware asynchronous Federated Learning algorithm with non-IID data",
		"title-short": "FedSA",
		"volume": "120",
		"author": [
			{
				"family": "Chen",
				"given": "Ming"
			},
			{
				"family": "Mao",
				"given": "Bingcheng"
			},
			{
				"family": "Ma",
				"given": "Tianyi"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2021"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/TFA4VWUB",
		"type": "article-journal",
		"container-title": "Advances in neural information processing systems",
		"source": "Google Scholar",
		"title": "More effective distributed ml via a stale synchronous parallel parameter server",
		"volume": "26",
		"author": [
			{
				"family": "Ho",
				"given": "Qirong"
			},
			{
				"family": "Cipar",
				"given": "James"
			},
			{
				"family": "Cui",
				"given": "Henggang"
			},
			{
				"family": "Lee",
				"given": "Seunghak"
			},
			{
				"family": "Kim",
				"given": "Jin Kyu"
			},
			{
				"family": "Gibbons",
				"given": "Phillip B."
			},
			{
				"family": "Gibson",
				"given": "Garth A."
			},
			{
				"family": "Ganger",
				"given": "Greg"
			},
			{
				"family": "Xing",
				"given": "Eric P."
			}
		],
		"issued": {
			"date-parts": [
				[
					"2013"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/WXD589FL",
		"type": "article-journal",
		"container-title": "arXiv preprint arXiv:1903.03934",
		"source": "Google Scholar",
		"title": "Asynchronous federated optimization",
		"author": [
			{
				"family": "Xie",
				"given": "Cong"
			},
			{
				"family": "Koyejo",
				"given": "Sanmi"
			},
			{
				"family": "Gupta",
				"given": "Indranil"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/9HQTNA8U",
		"type": "article-journal",
		"abstract": "In recent years, mobile devices are equipped with increasingly advanced sensing and computing capabilities. Coupled with advancements in Deep Learning (DL), this opens up countless possibilities for meaningful applications, e.g., for medical purposes and in vehicular networks. Traditional cloud-based Machine Learning (ML) approaches require the data to be centralized in a cloud server or data center. However, this results in critical issues related to unacceptable latency and communication inefficiency. To this end, Mobile Edge Computing (MEC) has been proposed to bring intelligence closer to the edge, where data is produced. However, conventional enabling technologies for ML at mobile edge networks still require personal data to be shared with external parties, e.g., edge servers. Recently, in light of increasingly stringent data privacy legislations and growing privacy concerns, the concept of Federated Learning (FL) has been introduced. In FL, end devices use their local data to train an ML model required by the server. The end devices then send the model updates rather than raw data to the server for aggregation. FL can serve as an enabling technology in mobile edge networks since it enables the collaborative training of an ML model and also enables DL for mobile edge network optimization. However, in a large-scale and complex mobile edge network, heterogeneous devices with varying constraints are involved. This raises challenges of communication costs, resource allocation, and privacy and security in the implementation of FL at scale. In this survey, we begin with an introduction to the background and fundamentals of FL. Then, we highlight the aforementioned challenges of FL implementation and review existing solutions. Furthermore, we present the applications of FL for mobile edge network optimization. Finally, we discuss the important challenges and future research directions in FL.",
		"container-title": "IEEE Communications Surveys & Tutorials",
		"DOI": "10.1109/COMST.2020.2986024",
		"ISSN": "1553-877X",
		"issue": "3",
		"note": "event-title: IEEE Communications Surveys & Tutorials",
		"page": "2031-2063",
		"source": "IEEE Xplore",
		"title": "Federated Learning in Mobile Edge Networks: A Comprehensive Survey",
		"title-short": "Federated Learning in Mobile Edge Networks",
		"volume": "22",
		"author": [
			{
				"family": "Lim",
				"given": "Wei Yang Bryan"
			},
			{
				"family": "Luong",
				"given": "Nguyen Cong"
			},
			{
				"family": "Hoang",
				"given": "Dinh Thai"
			},
			{
				"family": "Jiao",
				"given": "Yutao"
			},
			{
				"family": "Liang",
				"given": "Ying-Chang"
			},
			{
				"family": "Yang",
				"given": "Qiang"
			},
			{
				"family": "Niyato",
				"given": "Dusit"
			},
			{
				"family": "Miao",
				"given": "Chunyan"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2020"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/LUI5JXX5",
		"type": "article-journal",
		"container-title": "IEEE Journal on Selected Areas in Communications",
		"issue": "6",
		"note": "publisher: IEEE",
		"page": "1205–1221",
		"source": "Google Scholar",
		"title": "Adaptive federated learning in resource constrained edge computing systems",
		"volume": "37",
		"author": [
			{
				"family": "Wang",
				"given": "Shiqiang"
			},
			{
				"family": "Tuor",
				"given": "Tiffany"
			},
			{
				"family": "Salonidis",
				"given": "Theodoros"
			},
			{
				"family": "Leung",
				"given": "Kin K."
			},
			{
				"family": "Makaya",
				"given": "Christian"
			},
			{
				"family": "He",
				"given": "Ting"
			},
			{
				"family": "Chan",
				"given": "Kevin"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/KZW6BX6J",
		"type": "paper-conference",
		"container-title": "ICC 2019-2019 IEEE international conference on communications (ICC)",
		"page": "1–7",
		"publisher": "IEEE",
		"source": "Google Scholar",
		"title": "Client selection for federated learning with heterogeneous resources in mobile edge",
		"author": [
			{
				"family": "Nishio",
				"given": "Takayuki"
			},
			{
				"family": "Yonetani",
				"given": "Ryo"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/97MUXDU2",
		"type": "article-journal",
		"container-title": "arXiv preprint arXiv:1912.00513",
		"source": "Google Scholar",
		"title": "A quasi-newton method based vertical federated learning framework for logistic regression",
		"author": [
			{
				"family": "Yang",
				"given": "Kai"
			},
			{
				"family": "Fan",
				"given": "Tao"
			},
			{
				"family": "Chen",
				"given": "Tianjian"
			},
			{
				"family": "Shi",
				"given": "Yuanming"
			},
			{
				"family": "Yang",
				"given": "Qiang"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/MGL22TYC",
		"type": "article-journal",
		"container-title": "ACM Transactions on Intelligent Systems and Technology (TIST)",
		"issue": "2",
		"note": "publisher: ACM New York, NY, USA",
		"page": "1–19",
		"source": "Google Scholar",
		"title": "Federated machine learning: Concept and applications",
		"title-short": "Federated machine learning",
		"volume": "10",
		"author": [
			{
				"family": "Yang",
				"given": "Qiang"
			},
			{
				"family": "Liu",
				"given": "Yang"
			},
			{
				"family": "Chen",
				"given": "Tianjian"
			},
			{
				"family": "Tong",
				"given": "Yongxin"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/LZ37CWRI",
		"type": "paper-conference",
		"container-title": "Artificial intelligence and statistics",
		"page": "1273–1282",
		"publisher": "PMLR",
		"source": "Google Scholar",
		"title": "Communication-efficient learning of deep networks from decentralized data",
		"author": [
			{
				"family": "McMahan",
				"given": "Brendan"
			},
			{
				"family": "Moore",
				"given": "Eider"
			},
			{
				"family": "Ramage",
				"given": "Daniel"
			},
			{
				"family": "Hampson",
				"given": "Seth"
			},
			{
				"family": "Arcas",
				"given": "Blaise Aguera",
				"non-dropping-particle": "y"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2017"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/TX2KCLLI",
		"type": "paper-conference",
		"container-title": "2018 IEEE Global Communications Conference (GLOBECOM)",
		"page": "1–6",
		"publisher": "IEEE",
		"source": "Google Scholar",
		"title": "Federated learning based proactive content caching in edge computing",
		"author": [
			{
				"family": "Yu",
				"given": "Zhengxin"
			},
			{
				"family": "Hu",
				"given": "Jia"
			},
			{
				"family": "Min",
				"given": "Geyong"
			},
			{
				"family": "Lu",
				"given": "Haochuan"
			},
			{
				"family": "Zhao",
				"given": "Zhiwei"
			},
			{
				"family": "Wang",
				"given": "Haozhe"
			},
			{
				"family": "Georgalas",
				"given": "Nektarios"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2018"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/QMV3E4ED",
		"type": "paper-conference",
		"abstract": "We consider federated edge learning (FEEL), where mobile users (MUs) collaboratively learn a global model by sharing local updates on the model parameters rather than their datasets, with the help of a mobile base station (MBS). We optimize the resource allocation among MUs to reduce the communication latency in learning iterations. Observing that the performance in this centralized setting is limited due to the distance of the cell-edge users to the MBS, we introduce small cell base stations (SBSs) orchestrating FEEL among MUs within their cells, and periodically exchanging model updates with the MBS for global consensus. We show that this hierarchical federated learning (HFL) scheme significantly reduces the communication latency without sacrificing the accuracy.",
		"container-title": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
		"DOI": "10.1109/ICASSP40776.2020.9054634",
		"event-title": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
		"note": "ISSN: 2379-190X",
		"page": "8866-8870",
		"source": "IEEE Xplore",
		"title": "Hierarchical Federated Learning ACROSS Heterogeneous Cellular Networks",
		"author": [
			{
				"family": "Abad",
				"given": "M. S. H."
			},
			{
				"family": "Ozfatura",
				"given": "E."
			},
			{
				"family": "GUndUz",
				"given": "D."
			},
			{
				"family": "Ercetin",
				"given": "O."
			}
		],
		"issued": {
			"date-parts": [
				[
					"2020",
					5
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/M27ADF9J",
		"type": "article-journal",
		"container-title": "arXiv preprint arXiv:1909.05784",
		"source": "Google Scholar",
		"title": "Hhhfl: Hierarchical heterogeneous horizontal federated learning for electroencephalography",
		"title-short": "Hhhfl",
		"author": [
			{
				"family": "Gao",
				"given": "Dashan"
			},
			{
				"family": "Ju",
				"given": "Ce"
			},
			{
				"family": "Wei",
				"given": "Xiguang"
			},
			{
				"family": "Liu",
				"given": "Yang"
			},
			{
				"family": "Chen",
				"given": "Tianjian"
			},
			{
				"family": "Yang",
				"given": "Qiang"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/Y85DUGQJ",
		"type": "paper-conference",
		"container-title": "ICC 2020-2020 IEEE International Conference on Communications (ICC)",
		"page": "1–6",
		"publisher": "IEEE",
		"source": "Google Scholar",
		"title": "Client-edge-cloud hierarchical federated learning",
		"author": [
			{
				"family": "Liu",
				"given": "Lumin"
			},
			{
				"family": "Zhang",
				"given": "Jun"
			},
			{
				"family": "Song",
				"given": "S. H."
			},
			{
				"family": "Letaief",
				"given": "Khaled B."
			}
		],
		"issued": {
			"date-parts": [
				[
					"2020"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/HPTRSNXM",
		"type": "paper-conference",
		"container-title": "Proceedings of the 55th annual design automation conference",
		"page": "1–6",
		"source": "Google Scholar",
		"title": "Deepsecure: Scalable provably-secure deep learning",
		"title-short": "Deepsecure",
		"author": [
			{
				"family": "Rouhani",
				"given": "Bita Darvish"
			},
			{
				"family": "Riazi",
				"given": "M. Sadegh"
			},
			{
				"family": "Koushanfar",
				"given": "Farinaz"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2018"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/JIMYU56T",
		"type": "paper-conference",
		"container-title": "2017 IEEE symposium on security and privacy (SP)",
		"page": "19–38",
		"publisher": "IEEE",
		"source": "Google Scholar",
		"title": "Secureml: A system for scalable privacy-preserving machine learning",
		"title-short": "Secureml",
		"author": [
			{
				"family": "Mohassel",
				"given": "Payman"
			},
			{
				"family": "Zhang",
				"given": "Yupeng"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2017"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/Y99V8NU2",
		"type": "paper-conference",
		"container-title": "2016 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)",
		"page": "149–154",
		"publisher": "IEEE",
		"source": "Google Scholar",
		"title": "Cryptoml: Secure outsourcing of big data machine learning applications",
		"title-short": "Cryptoml",
		"author": [
			{
				"family": "Mirhoseini",
				"given": "Azalia"
			},
			{
				"family": "Sadeghi",
				"given": "Ahmad-Reza"
			},
			{
				"family": "Koushanfar",
				"given": "Farinaz"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2016"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/CZ4TCX74",
		"type": "paper-conference",
		"container-title": "Proceedings of the 22nd ACM SIGSAC conference on computer and communications security",
		"page": "1310–1321",
		"source": "Google Scholar",
		"title": "Privacy-preserving deep learning",
		"author": [
			{
				"family": "Shokri",
				"given": "Reza"
			},
			{
				"family": "Shmatikov",
				"given": "Vitaly"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2015"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/M267PPCU",
		"type": "paper-conference",
		"container-title": "Proceedings of the 2016 ACM SIGSAC conference on computer and communications security",
		"page": "308–318",
		"source": "Google Scholar",
		"title": "Deep learning with differential privacy",
		"author": [
			{
				"family": "Abadi",
				"given": "Martin"
			},
			{
				"family": "Chu",
				"given": "Andy"
			},
			{
				"family": "Goodfellow",
				"given": "Ian"
			},
			{
				"family": "McMahan",
				"given": "H. Brendan"
			},
			{
				"family": "Mironov",
				"given": "Ilya"
			},
			{
				"family": "Talwar",
				"given": "Kunal"
			},
			{
				"family": "Zhang",
				"given": "Li"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2016"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/JW7J54WT",
		"type": "paper-conference",
		"container-title": "International conference on machine learning",
		"page": "201–210",
		"publisher": "PMLR",
		"source": "Google Scholar",
		"title": "Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy",
		"title-short": "Cryptonets",
		"author": [
			{
				"family": "Gilad-Bachrach",
				"given": "Ran"
			},
			{
				"family": "Dowlin",
				"given": "Nathan"
			},
			{
				"family": "Laine",
				"given": "Kim"
			},
			{
				"family": "Lauter",
				"given": "Kristin"
			},
			{
				"family": "Naehrig",
				"given": "Michael"
			},
			{
				"family": "Wernsing",
				"given": "John"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2016"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/XAWFBGJC",
		"type": "paper-conference",
		"container-title": "International Conference on Information Security and Cryptology",
		"page": "1–21",
		"publisher": "Springer",
		"source": "Google Scholar",
		"title": "ML confidential: Machine learning on encrypted data",
		"title-short": "ML confidential",
		"author": [
			{
				"family": "Graepel",
				"given": "Thore"
			},
			{
				"family": "Lauter",
				"given": "Kristin"
			},
			{
				"family": "Naehrig",
				"given": "Michael"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2012"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/WL3S8J7N",
		"type": "article-journal",
		"container-title": "International Journal of Information Security",
		"issue": "4",
		"note": "publisher: Springer",
		"page": "365–377",
		"source": "Google Scholar",
		"title": "Supervised machine learning using encrypted training data",
		"volume": "17",
		"author": [
			{
				"family": "González-Serrano",
				"given": "Francisco-Javier"
			},
			{
				"family": "Amor-Martín",
				"given": "Adrián"
			},
			{
				"family": "Casamayón-Antón",
				"given": "Jorge"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2018"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/BZ3ZMQNY",
		"type": "paper-conference",
		"container-title": "International Conference on Selected Areas in Cryptography",
		"page": "453–478",
		"publisher": "Springer",
		"source": "Google Scholar",
		"title": "Unsupervised machine learning on encrypted data",
		"author": [
			{
				"family": "Jäschke",
				"given": "Angela"
			},
			{
				"family": "Armknecht",
				"given": "Frederik"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2018"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/7WSQ4XUA",
		"type": "article-journal",
		"container-title": "arXiv preprint arXiv:1711.05189",
		"source": "Google Scholar",
		"title": "Cryptodl: Deep neural networks over encrypted data",
		"title-short": "Cryptodl",
		"author": [
			{
				"family": "Hesamifard",
				"given": "Ehsan"
			},
			{
				"family": "Takabi",
				"given": "Hassan"
			},
			{
				"family": "Ghasemi",
				"given": "Mehdi"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2017"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/LPTG7DG4",
		"type": "article-journal",
		"container-title": "Cryptology ePrint Archive",
		"source": "Google Scholar",
		"title": "Privacy-preserving classification on deep neural network",
		"author": [
			{
				"family": "Chabanne",
				"given": "Hervé"
			},
			{
				"family": "De Wargny",
				"given": "Amaury"
			},
			{
				"family": "Milgram",
				"given": "Jonathan"
			},
			{
				"family": "Morel",
				"given": "Constance"
			},
			{
				"family": "Prouff",
				"given": "Emmanuel"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2017"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/TR6C8858",
		"type": "article-journal",
		"container-title": "Computer Standards & Interfaces",
		"note": "publisher: Elsevier",
		"page": "87–108",
		"source": "Google Scholar",
		"title": "Efficient machine learning over encrypted data with non-interactive communication",
		"volume": "58",
		"author": [
			{
				"family": "Park",
				"given": "Heejin"
			},
			{
				"family": "Kim",
				"given": "Pyung"
			},
			{
				"family": "Kim",
				"given": "Heeyoul"
			},
			{
				"family": "Park",
				"given": "Ki-Woong"
			},
			{
				"family": "Lee",
				"given": "Younho"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2018"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/UBGTT7VP",
		"type": "paper-conference",
		"container-title": "Proceedings of the 2018 ACM SIGSAC conference on computer and communications security",
		"page": "1209–1222",
		"source": "Google Scholar",
		"title": "Secure outsourced matrix computation and application to neural networks",
		"author": [
			{
				"family": "Jiang",
				"given": "Xiaoqian"
			},
			{
				"family": "Kim",
				"given": "Miran"
			},
			{
				"family": "Lauter",
				"given": "Kristin"
			},
			{
				"family": "Song",
				"given": "Yongsoo"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2018"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/X3YDD2ID",
		"type": "paper-conference",
		"container-title": "ICC 2020-2020 IEEE International Conference on Communications (ICC)",
		"page": "1–7",
		"publisher": "IEEE",
		"source": "Google Scholar",
		"title": "Hybrid-FL for wireless networks: Cooperative learning mechanism using non-IID data",
		"title-short": "Hybrid-FL for wireless networks",
		"author": [
			{
				"family": "Yoshida",
				"given": "Naoya"
			},
			{
				"family": "Nishio",
				"given": "Takayuki"
			},
			{
				"family": "Morikura",
				"given": "Masahiro"
			},
			{
				"family": "Yamamoto",
				"given": "Koji"
			},
			{
				"family": "Yonetani",
				"given": "Ryo"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2020"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/83AYYA68",
		"type": "article-journal",
		"container-title": "IEEE Internet of Things Journal",
		"issue": "7",
		"note": "publisher: IEEE",
		"page": "5986–5994",
		"source": "Google Scholar",
		"title": "Communication-efficient federated learning for wireless edge intelligence in IoT",
		"volume": "7",
		"author": [
			{
				"family": "Mills",
				"given": "Jed"
			},
			{
				"family": "Hu",
				"given": "Jia"
			},
			{
				"family": "Min",
				"given": "Geyong"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/BHTNNIFB",
		"type": "article-journal",
		"container-title": "IEEE Communications Magazine",
		"issue": "10",
		"note": "publisher: IEEE",
		"page": "88–93",
		"source": "Google Scholar",
		"title": "Federated learning for edge networks: Resource optimization and incentive mechanism",
		"title-short": "Federated learning for edge networks",
		"volume": "58",
		"author": [
			{
				"family": "Khan",
				"given": "Latif U."
			},
			{
				"family": "Pandey",
				"given": "Shashi Raj"
			},
			{
				"family": "Tran",
				"given": "Nguyen H."
			},
			{
				"family": "Saad",
				"given": "Walid"
			},
			{
				"family": "Han",
				"given": "Zhu"
			},
			{
				"family": "Nguyen",
				"given": "Minh NH"
			},
			{
				"family": "Hong",
				"given": "Choong Seon"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2020"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/X4UVUU2I",
		"type": "paper-conference",
		"container-title": "2019 IEEE Globecom Workshops (GC Wkshps)",
		"page": "1–6",
		"publisher": "IEEE",
		"source": "Google Scholar",
		"title": "On fully homomorphic encryption for privacy-preserving deep learning",
		"author": [
			{
				"family": "Marcano",
				"given": "Néstor J. Hernández"
			},
			{
				"family": "Moller",
				"given": "Mads"
			},
			{
				"family": "Hansen",
				"given": "Soren"
			},
			{
				"family": "Jacobsen",
				"given": "Rune Hylsberg"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/9G8SAUWZ",
		"type": "article-journal",
		"container-title": "ACM Transactions on Internet Technology (TOIT)",
		"issue": "3",
		"note": "publisher: ACM New York, NY",
		"page": "1–21",
		"source": "Google Scholar",
		"title": "Privacy-preserving time-series medical images analysis using a hybrid deep learning framework",
		"volume": "21",
		"author": [
			{
				"family": "Yue",
				"given": "Zijie"
			},
			{
				"family": "Ding",
				"given": "Shuai"
			},
			{
				"family": "Zhao",
				"given": "Lei"
			},
			{
				"family": "Zhang",
				"given": "Youtao"
			},
			{
				"family": "Cao",
				"given": "Zehong"
			},
			{
				"family": "Tanveer",
				"given": "Mohammad"
			},
			{
				"family": "Jolfaei",
				"given": "Alireza"
			},
			{
				"family": "Zheng",
				"given": "Xi"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2021"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/NXQK468T",
		"type": "article-journal",
		"container-title": "IEEE communications surveys & tutorials",
		"issue": "4",
		"note": "publisher: IEEE",
		"page": "2322–2358",
		"source": "Google Scholar",
		"title": "A survey on mobile edge computing: The communication perspective",
		"title-short": "A survey on mobile edge computing",
		"volume": "19",
		"author": [
			{
				"family": "Mao",
				"given": "Yuyi"
			},
			{
				"family": "You",
				"given": "Changsheng"
			},
			{
				"family": "Zhang",
				"given": "Jun"
			},
			{
				"family": "Huang",
				"given": "Kaibin"
			},
			{
				"family": "Letaief",
				"given": "Khaled B."
			}
		],
		"issued": {
			"date-parts": [
				[
					"2017"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/LZY74EBN",
		"type": "paper-conference",
		"abstract": "Federated learning is an emerging collaborative machine-learning paradigm for training models directly on edge devices. The data remains on the edge device and this method is robust under real-world edge data distributions. We present a new asynchronous federated-learning algorithm (‘asynchronous federated learning’) and study its convergence rate when distributed across many edge devices, with hard data constraints, relative to training the same model on a single device. We compare asynchronous federated learning to an existing synchronous method. We evaluate its robustness in real-world situations; for example, devices joining part-way through training or devices with heterogeneous compute resources. We then apply asynchronous federated learning to a challenging geospatial application, namely image-based geolocation using a state-of-the-art convolutional neural network. Our results lay the groundwork for deploying large-scale federated learning as a tool to automatically learn, and continually update, a machine-learned model that encodes location.",
		"collection-title": "Communications in Computer and Information Science",
		"container-title": "ECML PKDD 2018 Workshops",
		"DOI": "10.1007/978-3-030-14880-5_2",
		"event-place": "Cham",
		"ISBN": "978-3-030-14880-5",
		"language": "en",
		"page": "21-28",
		"publisher": "Springer International Publishing",
		"publisher-place": "Cham",
		"source": "Springer Link",
		"title": "Asynchronous Federated Learning for Geospatial Applications",
		"author": [
			{
				"family": "Sprague",
				"given": "Michael R."
			},
			{
				"family": "Jalalirad",
				"given": "Amir"
			},
			{
				"family": "Scavuzzo",
				"given": "Marco"
			},
			{
				"family": "Capota",
				"given": "Catalin"
			},
			{
				"family": "Neun",
				"given": "Moritz"
			},
			{
				"family": "Do",
				"given": "Lyman"
			},
			{
				"family": "Kopp",
				"given": "Michael"
			}
		],
		"editor": [
			{
				"family": "Monreale",
				"given": "Anna"
			},
			{
				"family": "Alzate",
				"given": "Carlos"
			},
			{
				"family": "Kamp",
				"given": "Michael"
			},
			{
				"family": "Krishnamurthy",
				"given": "Yamuna"
			},
			{
				"family": "Paurat",
				"given": "Daniel"
			},
			{
				"family": "Sayed-Mouchaweh",
				"given": "Moamar"
			},
			{
				"family": "Bifet",
				"given": "Albert"
			},
			{
				"family": "Gama",
				"given": "João"
			},
			{
				"family": "Ribeiro",
				"given": "Rita P."
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/RTQQUZU5",
		"type": "article",
		"abstract": "Federated learning (FL) involves training a model over massive distributed devices, while keeping the training data localized. This form of collaborative learning exposes new tradeoffs among model convergence speed, model accuracy, balance across clients, and communication cost, with new challenges including: (1) straggler problem, where the clients lag due to data or (computing and network) resource heterogeneity, and (2) communication bottleneck, where a large number of clients communicate their local updates to a central server and bottleneck the server. Many existing FL methods focus on optimizing along only one dimension of the tradeoff space. Existing solutions use asynchronous model updating or tiering-based synchronous mechanisms to tackle the straggler problem. However, the asynchronous methods can easily create a network communication bottleneck, while tiering may introduce biases as tiering favors faster tiers with shorter response latencies. To address these issues, we present FedAT, a novel Federated learning method with Asynchronous Tiers under Non-i.i.d. data. FedAT synergistically combines synchronous intra-tier training and asynchronous cross-tier training. By bridging the synchronous and asynchronous training through tiering, FedAT minimizes the straggler effect with improved convergence speed and test accuracy. FedAT uses a straggler-aware, weighted aggregation heuristic to steer and balance the training for further accuracy improvement. FedAT compresses the uplink and downlink communications using an efficient, polyline-encoding-based compression algorithm, therefore minimizing the communication cost. Results show that FedAT improves the prediction performance by up to 21.09%, and reduces the communication cost by up to 8.5x, compared to state-of-the-art FL methods.",
		"DOI": "10.48550/arXiv.2010.05958",
		"note": "arXiv:2010.05958 [cs]",
		"number": "arXiv:2010.05958",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "FedAT: A High-Performance and Communication-Efficient Federated Learning System with Asynchronous Tiers",
		"title-short": "FedAT",
		"URL": "http://arxiv.org/abs/2010.05958",
		"author": [
			{
				"family": "Chai",
				"given": "Zheng"
			},
			{
				"family": "Chen",
				"given": "Yujing"
			},
			{
				"family": "Anwar",
				"given": "Ali"
			},
			{
				"family": "Zhao",
				"given": "Liang"
			},
			{
				"family": "Cheng",
				"given": "Yue"
			},
			{
				"family": "Rangwala",
				"given": "Huzefa"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2022",
					11,
					5
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2021",
					8,
					28
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/DUVR77EP",
		"type": "article",
		"abstract": "In this paper, we propose Helios, a heterogeneity-aware FL framework to tackle the straggler issue. Helios identifies individual devices' heterogeneous training capability, and therefore the expected neural network model training volumes regarding the collaborative training pace. For straggling devices, a \"soft-training\" method is proposed to dynamically compress the original identical training model into the expected volume through a rotating neuron training approach. With extensive algorithm analysis and optimization schemes, the stragglers can be accelerated while retaining the convergence for local training as well as federated collaboration.",
		"note": "arXiv:1912.01684 [cs]",
		"number": "arXiv:1912.01684",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Helios: Heterogeneity-Aware Federated Learning with Dynamically Balanced Collaboration",
		"title-short": "Helios",
		"URL": "http://arxiv.org/abs/1912.01684",
		"author": [
			{
				"family": "Xu",
				"given": "Zirui"
			},
			{
				"family": "Yu",
				"given": "Fuxun"
			},
			{
				"family": "Xiong",
				"given": "Jinjun"
			},
			{
				"family": "Chen",
				"given": "Xiang"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2022",
					11,
					5
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2021",
					3,
					1
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/JRZJT3VP",
		"type": "paper-conference",
		"container-title": "International conference on the theory and application of cryptology and information security",
		"page": "409–437",
		"publisher": "Springer",
		"source": "Google Scholar",
		"title": "Homomorphic encryption for arithmetic of approximate numbers",
		"author": [
			{
				"family": "Cheon",
				"given": "Jung Hee"
			},
			{
				"family": "Kim",
				"given": "Andrey"
			},
			{
				"family": "Kim",
				"given": "Miran"
			},
			{
				"family": "Song",
				"given": "Yongsoo"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2017"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/CN8NDN4A",
		"type": "article-journal",
		"container-title": "Cryptology ePrint Archive",
		"source": "Google Scholar",
		"title": "Somewhat practical fully homomorphic encryption",
		"author": [
			{
				"family": "Fan",
				"given": "Junfeng"
			},
			{
				"family": "Vercauteren",
				"given": "Frederik"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2012"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/PXYR9LE4",
		"type": "article-journal",
		"abstract": "Federated learning is an emerging machine learning technique that enables distributed model training using local datasets from large-scale nodes, e.g., mobile devices, but shares only model updates without uploading the raw training data. This technique provides a promising privacy preservation for mobile devices while simultaneously ensuring high learning performance. The majority of existing work has focused on designing advanced learning algorithms with an aim to achieve better learning performance. However, the challenges, such as incentive mechanisms for participating in training and worker (i.e., mobile devices) selection schemes for reliable federated learning, have not been explored yet. These challenges have hindered the widespread adoption of federated learning. To address the above challenges, in this article, we first introduce reputation as the metric to measure the reliability and trustworthiness of the mobile devices. We then design a reputation-based worker selection scheme for reliable federated learning by using a multiweight subjective logic model. We also leverage the blockchain to achieve secure reputation management for workers with nonrepudiation and tamper-resistance properties in a decentralized manner. Moreover, we propose an effective incentive mechanism combining reputation with contract theory to motivate high-reputation mobile devices with high-quality data to participate in model learning. Numerical results clearly indicate that the proposed schemes are efficient for reliable federated learning in terms of significantly improving the learning accuracy.",
		"container-title": "IEEE Internet of Things Journal",
		"DOI": "10.1109/JIOT.2019.2940820",
		"ISSN": "2327-4662",
		"issue": "6",
		"note": "event-title: IEEE Internet of Things Journal",
		"page": "10700-10714",
		"source": "IEEE Xplore",
		"title": "Incentive Mechanism for Reliable Federated Learning: A Joint Optimization Approach to Combining Reputation and Contract Theory",
		"title-short": "Incentive Mechanism for Reliable Federated Learning",
		"volume": "6",
		"author": [
			{
				"family": "Kang",
				"given": "Jiawen"
			},
			{
				"family": "Xiong",
				"given": "Zehui"
			},
			{
				"family": "Niyato",
				"given": "Dusit"
			},
			{
				"family": "Xie",
				"given": "Shengli"
			},
			{
				"family": "Zhang",
				"given": "Junshan"
			}
		],
		"issued": {
			"date-parts": [
				[
					"2019",
					12
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/9765969/items/WJXQJPGB",
		"type": "webpage",
		"title": "Privacy or Utility in Data Collection? A Contract Theoretic Approach | IEEE Journals & Magazine | IEEE Xplore",
		"URL": "https://ieeexplore-ieee-org.ezproxy.lib.uts.edu.au/document/7093125",
		"accessed": {
			"date-parts": [
				[
					"2022",
					11,
					18
				]
			]
		}
	}
]